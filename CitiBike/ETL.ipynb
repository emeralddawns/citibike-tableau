{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a43c0b2-5d0e-4328-bfd4-5cc121fcfded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pymongo\n",
    "import lxml\n",
    "import wget\n",
    "import zipfile\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d0aca7-c7ef-4ae4-bb81-8bb955c14fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome with the command:  powershell \"$ErrorActionPreference='silentlycontinue' ; (Get-Item -Path \"$env:PROGRAMFILES\\Google\\Chrome\\Application\\chrome.exe\").VersionInfo.FileVersion ; if (-not $? -or $? -match $error) { (Get-Item -Path \"$env:PROGRAMFILES(x86)\\Google\\Chrome\\Application\\chrome.exe\").VersionInfo.FileVersion } if (-not $? -or $? -match $error) { (Get-Item -Path \"$env:LOCALAPPDATA\\Google\\Chrome\\Application\\chrome.exe\").VersionInfo.FileVersion } if (-not $? -or $? -match $error) { reg query \"HKCU\\SOFTWARE\\Google\\Chrome\\BLBeacon\" /v version } if (-not $? -or $? -match $error) { reg query \"HKLM\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\Google Chrome\" /v version }\"\n",
      "Current google-chrome version is UNKNOWN\n",
      "Get LATEST chromedriver version for UNKNOWN google-chrome\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/101.0.4951.41/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\emera\\.wdm\\drivers\\chromedriver\\win32\\101.0.4951.41]\n"
     ]
    }
   ],
   "source": [
    "# Set up splinter because \"view source\" doesn't match \"inspect\"\n",
    "\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2c1030c-926e-476c-a286-3509cc6aa598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = \"https://s3.amazonaws.com/tripdata/index.html\"\n",
    "\n",
    "# Visit the browser\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40598b3-89d5-4313-98d1-b5b8092e5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT merge this cell with the cell above (url=...), the web page needs time to load all the links in\n",
    "# Set up BeautifulSoup\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b4c8eab-c00e-40e6-b138-a6def92af153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://s3.amazonaws.com/tripdata/201306-citibike-tripdata.zip\">201306-citibike-tripdata.zip</a>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the tag containing the desired information\n",
    "results = soup.find_all('a', class_='')\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e98d24-9663-4ff2-ac98-3aa4f74d6add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of years, and names for the subsequent lists\n",
    "years_list = []\n",
    "names_list = []\n",
    "\n",
    "for i in range(0, (len(results) - 1 )): # the \"-1\" will filter out index.html\n",
    "    \n",
    "    # extract the date\n",
    "    date = results[i][\"href\"].split('/')[-1].split('-')[0]\n",
    "    \n",
    "    # filter out Jersey City (JC) data\n",
    "    if (date != \"JC\"):\n",
    "        \n",
    "        # Extract the year\n",
    "        year = int(date[0:4])\n",
    "                \n",
    "        if (year not in years_list):\n",
    "            \n",
    "            # Add the found year to the years_list\n",
    "            years_list.append(year)\n",
    "            \n",
    "            # Create name, append to list\n",
    "            name = f\"data_{year}\"\n",
    "            names_list.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b0aaf9-9808-4457-9e73-07452133e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names_list:\n",
    "    globals()[f\"{name}\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ee2f16e-c79e-446d-9e51-5aeb0c1d5867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through every link in the list\n",
    "for i in range(0, (len(results) - 1 )): # the \"-1\" will filter out index.html\n",
    "    \n",
    "    # Find the date\n",
    "    date = results[i][\"href\"].split('/')[-1].split('-')[0]\n",
    "    \n",
    "    # filter out Jersey City (JC) data\n",
    "    if (date != \"JC\"):\n",
    "        \n",
    "        # Find the year\n",
    "        year = int(date[0:4])\n",
    "\n",
    "        # Loop through every list\n",
    "        for j in range (0, len(names_list)):\n",
    "\n",
    "            if (year == years_list[j]):\n",
    "                \n",
    "                # Append any applicable link to the list\n",
    "                globals()[f\"{names_list[j]}\"].append(results[i][\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf9e09d6-b03a-4f2b-bb0c-55fcf61ef305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose a year between 2013 and 2022: 2022\n"
     ]
    }
   ],
   "source": [
    "year_selection = input(f\"Choose a year between {years_list[0]} and {years_list[-1]}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "248be780-978f-4c2b-8c38-4b8c8877f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = globals()[f\"data_{year_selection}\"]\n",
    "\n",
    "# Limit can be reduced for testing purposes, use len(selected_data) to run the remaining code for all files returned\n",
    "limit = len(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28ce9eb2-d9e4-4b59-b3e8-db6ea3a3b701",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [....................................................] 66434482 / 66434482"
     ]
    }
   ],
   "source": [
    "# Create lists of zip names and csv names to use when calling the file\n",
    "zip_names = []\n",
    "csv_names = []\n",
    "\n",
    "# for entry in results:\n",
    "for i in range(0, limit):\n",
    "    \n",
    "    # Get the link\n",
    "    link = selected_data[i]\n",
    "\n",
    "    # Use the link to get the zip and csv names, in case the .text is mismatched\n",
    "    zip_name = link.split('/')[-1]\n",
    "    zip_names.append(zip_name)\n",
    "\n",
    "    csv_name = zip_name.split('.')[0] + \".csv\"\n",
    "    csv_names.append(csv_name)\n",
    "   \n",
    "    # Download the zip\n",
    "    wget.download(link, out = \"zipfiles\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a50af4aa-6e05-404b-b472-bf9c88e0159b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emera\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (5,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\Users\\emera\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (5,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\Users\\emera\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (5,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#Create CSVs\n",
    "\n",
    "#Set up the station information data frame and tracker list\n",
    "station_df = pd.DataFrame(columns = ['station_name', 'station_id', 'latitude', 'longitude'])\n",
    "station_names = []\n",
    "\n",
    "for i in range(0, limit):\n",
    "    \n",
    "    # Drop nulls\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # find and read the zip file\n",
    "    find_zip = \"zipfiles/\" + zip_names[i]\n",
    "    zf = zipfile.ZipFile(find_zip)\n",
    "    df = pd.read_csv(zf.open(csv_names[i]))\n",
    "\n",
    "    # Add to the station_data df\n",
    "    for index, row in df.iterrows():\n",
    "        # Capturing station information from the start station\n",
    "        if row[\"start_station_name\"] not in station_names:\n",
    "            start_station_name = row[\"start_station_name\"] \n",
    "            start_station_id = row[\"start_station_id\"] \n",
    "            start_lat = row[\"start_lat\"]\n",
    "            start_lng = row[\"start_lng\"]\n",
    "            \n",
    "            # Append a new row\n",
    "            station_df = station_df.append({'station_name': start_station_name, 'station_id': start_station_id, 'latitude': start_lat, 'longitude': start_lng}, ignore_index = True)\n",
    "\n",
    "            # Add to the tracker list\n",
    "            station_names.append(start_station_name)\n",
    "\n",
    "    # Create new, smaller dataframe with extraneous station data removed\n",
    "    reduced_df = df[[\"ride_id\", \"rideable_type\", \"started_at\", \"ended_at\", \"start_station_id\", \"end_station_id\", \"member_casual\"]].copy()\n",
    "    \n",
    "    # Create a trip duration column\n",
    "    reduced_df[\"ended_at\"] = pd.to_datetime(reduced_df[\"ended_at\"], format='%Y-%m-%d %H:%M:%S')\n",
    "    reduced_df[\"started_at\"] = pd.to_datetime(reduced_df[\"started_at\"], format='%Y-%m-%d %H:%M:%S')\n",
    "    reduced_df[\"trip_duration_s\"] = (reduced_df[\"ended_at\"] - reduced_df[\"started_at\"]).dt.total_seconds()\n",
    "     \n",
    "    #create the csv\n",
    "    reduced_df.to_csv(\"data/\" + csv_names[i], index = False)\n",
    "\n",
    "#Save the station dataframe as a CSV\n",
    "station_df.to_csv(\"data/station_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3ee770f-6f5e-4401-8b2b-9bfa5f4a91aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>trip_duration_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72D1C9F1A2FEB359</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-12-04 17:53:23</td>\n",
       "      <td>2021-12-04 18:05:37</td>\n",
       "      <td>4695.04</td>\n",
       "      <td>4713.01</td>\n",
       "      <td>casual</td>\n",
       "      <td>734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8BE7469E1A90508C</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2021-12-04 17:35:04</td>\n",
       "      <td>2021-12-04 17:52:55</td>\n",
       "      <td>6215.04</td>\n",
       "      <td>6416.06</td>\n",
       "      <td>casual</td>\n",
       "      <td>1071.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF9EDCC2A347E607</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2021-12-13 23:59:41</td>\n",
       "      <td>2021-12-14 00:08:31</td>\n",
       "      <td>4695.04</td>\n",
       "      <td>5002.09</td>\n",
       "      <td>casual</td>\n",
       "      <td>530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>495CF3C8A1B7FED8</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-12-22 12:22:38</td>\n",
       "      <td>2021-12-22 12:25:46</td>\n",
       "      <td>7627.1</td>\n",
       "      <td>7617.07</td>\n",
       "      <td>member</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1C138E3D55FCC7C1</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-12-16 10:15:22</td>\n",
       "      <td>2021-12-16 10:32:02</td>\n",
       "      <td>6382.05</td>\n",
       "      <td>5569.06</td>\n",
       "      <td>member</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748282</th>\n",
       "      <td>714D3CCFB28DC79C</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-12-06 15:33:18</td>\n",
       "      <td>2021-12-06 15:42:18</td>\n",
       "      <td>6239.08</td>\n",
       "      <td>5947.04</td>\n",
       "      <td>member</td>\n",
       "      <td>540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748283</th>\n",
       "      <td>1A2F3968E4A735FB</td>\n",
       "      <td>docked_bike</td>\n",
       "      <td>2021-12-11 14:24:00</td>\n",
       "      <td>2021-12-12 13:58:42</td>\n",
       "      <td>5797.01</td>\n",
       "      <td>5593.02</td>\n",
       "      <td>casual</td>\n",
       "      <td>84882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748284</th>\n",
       "      <td>1BD68D08120346F9</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-12-05 14:15:22</td>\n",
       "      <td>2021-12-05 14:23:28</td>\n",
       "      <td>4565.04</td>\n",
       "      <td>4413.08</td>\n",
       "      <td>member</td>\n",
       "      <td>486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748285</th>\n",
       "      <td>F7D2A9EAE112CF48</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2021-12-31 11:22:45</td>\n",
       "      <td>2021-12-31 11:57:19</td>\n",
       "      <td>4683.02</td>\n",
       "      <td>3955.05</td>\n",
       "      <td>member</td>\n",
       "      <td>2074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748286</th>\n",
       "      <td>E97EDE10E6EE672F</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2021-12-20 18:08:26</td>\n",
       "      <td>2021-12-20 18:20:36</td>\n",
       "      <td>4596.09</td>\n",
       "      <td>5270.05</td>\n",
       "      <td>member</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1748287 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ride_id  rideable_type          started_at  \\\n",
       "0        72D1C9F1A2FEB359   classic_bike 2021-12-04 17:53:23   \n",
       "1        8BE7469E1A90508C  electric_bike 2021-12-04 17:35:04   \n",
       "2        AF9EDCC2A347E607  electric_bike 2021-12-13 23:59:41   \n",
       "3        495CF3C8A1B7FED8   classic_bike 2021-12-22 12:22:38   \n",
       "4        1C138E3D55FCC7C1   classic_bike 2021-12-16 10:15:22   \n",
       "...                   ...            ...                 ...   \n",
       "1748282  714D3CCFB28DC79C   classic_bike 2021-12-06 15:33:18   \n",
       "1748283  1A2F3968E4A735FB    docked_bike 2021-12-11 14:24:00   \n",
       "1748284  1BD68D08120346F9   classic_bike 2021-12-05 14:15:22   \n",
       "1748285  F7D2A9EAE112CF48   classic_bike 2021-12-31 11:22:45   \n",
       "1748286  E97EDE10E6EE672F  electric_bike 2021-12-20 18:08:26   \n",
       "\n",
       "                   ended_at start_station_id end_station_id member_casual  \\\n",
       "0       2021-12-04 18:05:37          4695.04        4713.01        casual   \n",
       "1       2021-12-04 17:52:55          6215.04        6416.06        casual   \n",
       "2       2021-12-14 00:08:31          4695.04        5002.09        casual   \n",
       "3       2021-12-22 12:25:46           7627.1        7617.07        member   \n",
       "4       2021-12-16 10:32:02          6382.05        5569.06        member   \n",
       "...                     ...              ...            ...           ...   \n",
       "1748282 2021-12-06 15:42:18          6239.08        5947.04        member   \n",
       "1748283 2021-12-12 13:58:42          5797.01        5593.02        casual   \n",
       "1748284 2021-12-05 14:23:28          4565.04        4413.08        member   \n",
       "1748285 2021-12-31 11:57:19          4683.02        3955.05        member   \n",
       "1748286 2021-12-20 18:20:36          4596.09        5270.05        member   \n",
       "\n",
       "         trip_duration_s  \n",
       "0                  734.0  \n",
       "1                 1071.0  \n",
       "2                  530.0  \n",
       "3                  188.0  \n",
       "4                 1000.0  \n",
       "...                  ...  \n",
       "1748282            540.0  \n",
       "1748283          84882.0  \n",
       "1748284            486.0  \n",
       "1748285           2074.0  \n",
       "1748286            730.0  \n",
       "\n",
       "[1748287 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72af0f0f-6f68-4bf8-98c3-d82d35b6a9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>station_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington St &amp; Barrow St</td>\n",
       "      <td>5847.08</td>\n",
       "      <td>40.731911</td>\n",
       "      <td>-74.008769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 Ave &amp; E 110 St</td>\n",
       "      <td>7522.02</td>\n",
       "      <td>40.792327</td>\n",
       "      <td>-73.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crescent St &amp; Broadway</td>\n",
       "      <td>6827.11</td>\n",
       "      <td>40.763359</td>\n",
       "      <td>-73.928647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stagg St &amp; Union Ave</td>\n",
       "      <td>5117.05</td>\n",
       "      <td>40.708771</td>\n",
       "      <td>-73.950953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frost St &amp; Meeker Ave</td>\n",
       "      <td>5371.07</td>\n",
       "      <td>40.717662</td>\n",
       "      <td>-73.948800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>Cauldwell Ave &amp; E 158 St</td>\n",
       "      <td>7913.15</td>\n",
       "      <td>40.819890</td>\n",
       "      <td>-73.908351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>Townsend Ave &amp; E 175 St</td>\n",
       "      <td>8323.05</td>\n",
       "      <td>40.847410</td>\n",
       "      <td>-73.911359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>63 St &amp; 5 Ave</td>\n",
       "      <td>2872.02</td>\n",
       "      <td>40.637660</td>\n",
       "      <td>-74.017820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.670000</td>\n",
       "      <td>-73.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>Morgan WH station</td>\n",
       "      <td>SYS032</td>\n",
       "      <td>40.709873</td>\n",
       "      <td>-73.931594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1544 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   station_name station_id   latitude  longitude\n",
       "0     Washington St & Barrow St    5847.08  40.731911 -74.008769\n",
       "1              1 Ave & E 110 St    7522.02  40.792327 -73.938300\n",
       "2        Crescent St & Broadway    6827.11  40.763359 -73.928647\n",
       "3          Stagg St & Union Ave    5117.05  40.708771 -73.950953\n",
       "4         Frost St & Meeker Ave    5371.07  40.717662 -73.948800\n",
       "...                         ...        ...        ...        ...\n",
       "1539   Cauldwell Ave & E 158 St    7913.15  40.819890 -73.908351\n",
       "1540    Townsend Ave & E 175 St    8323.05  40.847410 -73.911359\n",
       "1541              63 St & 5 Ave    2872.02  40.637660 -74.017820\n",
       "1542                        NaN        NaN  40.670000 -73.970000\n",
       "1543          Morgan WH station     SYS032  40.709873 -73.931594\n",
       "\n",
       "[1544 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "station_df = pd.DataFrame(columns = ['station_name', 'station_id', 'latitude', 'longitude'])\n",
    "\n",
    "station_names = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    \n",
    "    # Capturing station information from the start station\n",
    "    if row[\"start_station_name\"] not in station_names:\n",
    "        start_station_name = row[\"start_station_name\"] \n",
    "        start_station_id = row[\"start_station_id\"] \n",
    "        start_lat = row[\"start_lat\"]\n",
    "        start_lng = row[\"start_lng\"]\n",
    "    \n",
    "        station_df = station_df.append({'station_name': start_station_name, 'station_id': start_station_id, 'latitude': start_lat, 'longitude': start_lng}, ignore_index = True)\n",
    "    \n",
    "        station_names.append(start_station_name)\n",
    "\n",
    "station_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a81958a-7af7-4ffc-a43a-02983763d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df.to_csv(\"data/station_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "243597b4-7aff-4a79-8ca7-c14860cb957b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'202201-citibike-tripdata.csv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b434016-15e9-4fc5-b83b-a86612f902ed",
   "metadata": {},
   "source": [
    "### Next up: Turn all station info into a separate smaller csv/table, remove NULL values, ...remove outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee89a7-350b-4540-9ef0-26802a789648",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a3b39-bc3d-4aec-a189-c6012ac8e08f",
   "metadata": {},
   "source": [
    "### OLD Code with non-dynamic list names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4591a16-3fae-4b3f-8281-714c3151c3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://s3.amazonaws.com/tripdata/202201-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/202202-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/202203-citibike-tripdata.csv.zip']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2013to2016 = []\n",
    "data_2017 = []\n",
    "data_2018 = []\n",
    "data_2019 = []\n",
    "data_2020 = []\n",
    "data_2021 = []\n",
    "data_2022 = []\n",
    "\n",
    "\n",
    "for i in range(0, (len(results) - 1 )): # the \"-1\" will filter out index.html\n",
    "    date = results[i][\"href\"].split('/')[-1].split('-')[0]\n",
    "    \n",
    "    # filter out Jersey City (JC) data\n",
    "    if (date != \"JC\"):\n",
    "        year = int(date[0:4])\n",
    "        if (year <= 2016):\n",
    "            data_2013to2016.append(results[i][\"href\"])\n",
    "        elif (year == 2017):\n",
    "            data_2017.append(results[i][\"href\"])\n",
    "        elif (year == 2018):\n",
    "            data_2018.append(results[i][\"href\"])\n",
    "        elif (year == 2019):\n",
    "            data_2019.append(results[i][\"href\"])\n",
    "        elif (year == 2020):\n",
    "            data_2020.append(results[i][\"href\"])\n",
    "        elif (year == 2021):\n",
    "            data_2021.append(results[i][\"href\"])\n",
    "        elif (year == 2022):\n",
    "            data_2022.append(results[i][\"href\"])\n",
    "           \n",
    "            \n",
    "data_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a70f8365-0c92-4acd-aafd-4055091ac17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download zip files for a given year or year set\n",
    "data_list = data_2022\n",
    "\n",
    "limit = len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d33166fa-ff64-4130-8b47-ff2f6cf51ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [....................................................] 66434482 / 66434482"
     ]
    }
   ],
   "source": [
    "# Create lists of zip names and csv names to use when calling the file\n",
    "zip_names = []\n",
    "csv_names = []\n",
    "\n",
    "# for entry in results:\n",
    "for i in range(0, limit):\n",
    "    \n",
    "    # Get the link\n",
    "    link = data_list[i]\n",
    "\n",
    "    # Use the link to get the zip and csv names, in case the .text is mismatched\n",
    "    zip_name = link.split('/')[-1]\n",
    "    zip_names.append(zip_name)\n",
    "\n",
    "    csv_name = zip_name.split('.')[0] + \".csv\"\n",
    "    csv_names.append(csv_name)\n",
    "   \n",
    "    # Download the zip\n",
    "    wget.download(link, out = \"zipfiles\") \n",
    "    \n",
    "#     # Open and save as CSV\n",
    "#     df = pd.read_csv(zf.open(csv_names[i]))\n",
    "#     df.name = csv_names[i]\n",
    "#     df.to_csv(\"CSVs\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c66aa27c-3515-4390-8e3c-f52e59465b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emera\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (5,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#Save as CSVs\n",
    "\n",
    "for i in range(0, limit):\n",
    "    \n",
    "    # find and read the zip file\n",
    "    find_zip = \"zipfiles/\" + zip_names[i]\n",
    "    zf = zipfile.ZipFile(find_zip)\n",
    "    df = pd.read_csv(zf.open(csv_names[i]))\n",
    "    \n",
    "    # name and create the csv\n",
    "    df.name = csv_names[i]\n",
    "    df.to_csv(\"data/\" + csv_names[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "529d6b01-18c3-4beb-aa10-010f987cbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/202112-citibike-tripdata.csv\")\n",
    "df[\"ended_at\"] = pd.to_datetime(df[\"ended_at\"], format='%Y-%m-%d %H:%M:%S')\n",
    "df[\"started_at\"] = pd.to_datetime(df[\"started_at\"], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d99acb2c-d79b-40fb-bdf8-7834c309ee16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            734.0\n",
       "1           1071.0\n",
       "2            530.0\n",
       "3            188.0\n",
       "4           1000.0\n",
       "            ...   \n",
       "1748282      540.0\n",
       "1748283    84882.0\n",
       "1748284      486.0\n",
       "1748285     2074.0\n",
       "1748286      730.0\n",
       "Name: trip_duration_s, Length: 1748287, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"trip_duration_s\"] = (df[\"ended_at\"] - df[\"started_at\"]).dt.total_seconds()\n",
    "df[\"trip_duration_s\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a0eb1a6-9bfc-489b-8e54-1868267db2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ride_id             1739723\n",
       "rideable_type       1739723\n",
       "started_at          1739723\n",
       "ended_at            1739723\n",
       "start_station_id    1739723\n",
       "end_station_id      1739723\n",
       "member_casual       1739723\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a21b99e4-2a4f-41cc-914a-3f9f41b3ace6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      1570\n",
       "station_name    1569\n",
       "station_id      1569\n",
       "latitude        1570\n",
       "longitude       1570\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/station_data.csv\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90641fc0-497b-4421-9ed5-1d68e52b0aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      1569\n",
       "station_name    1569\n",
       "station_id      1569\n",
       "latitude        1569\n",
       "longitude       1569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b5405c5-b097-4a85-83f7-13fbe7d82eef",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-344ad8df2dc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'str'"
     ]
    }
   ],
   "source": [
    "df = df[df[\"station_name\"].str.strip().astype(bool)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
