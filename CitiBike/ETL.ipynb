{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a43c0b2-5d0e-4328-bfd4-5cc121fcfded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pymongo\n",
    "import lxml\n",
    "import wget\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d0aca7-c7ef-4ae4-bb81-8bb955c14fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Could not get version for google-chrome with the command:  powershell \"$ErrorActionPreference='silentlycontinue' ; (Get-Item -Path \"$env:PROGRAMFILES\\Google\\Chrome\\Application\\chrome.exe\").VersionInfo.FileVersion ; if (-not $? -or $? -match $error) { (Get-Item -Path \"$env:PROGRAMFILES(x86)\\Google\\Chrome\\Application\\chrome.exe\").VersionInfo.FileVersion } if (-not $? -or $? -match $error) { (Get-Item -Path \"$env:LOCALAPPDATA\\Google\\Chrome\\Application\\chrome.exe\").VersionInfo.FileVersion } if (-not $? -or $? -match $error) { reg query \"HKCU\\SOFTWARE\\Google\\Chrome\\BLBeacon\" /v version } if (-not $? -or $? -match $error) { reg query \"HKLM\\SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall\\Google Chrome\" /v version }\"\n",
      "Current google-chrome version is UNKNOWN\n",
      "Get LATEST chromedriver version for UNKNOWN google-chrome\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/101.0.4951.41/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\emera\\.wdm\\drivers\\chromedriver\\win32\\101.0.4951.41]\n"
     ]
    }
   ],
   "source": [
    "# Set up splinter because \"view source\" doesn't match \"inspect\"\n",
    "\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2c1030c-926e-476c-a286-3509cc6aa598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "url = \"https://s3.amazonaws.com/tripdata/index.html\"\n",
    "\n",
    "# Visit the browser\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40598b3-89d5-4313-98d1-b5b8092e5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT merge this cell with the cell above (url=...), the web page needs time to load all the links in\n",
    "# Set up BeautifulSoup\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b4c8eab-c00e-40e6-b138-a6def92af153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://s3.amazonaws.com/tripdata/201306-citibike-tripdata.zip\">201306-citibike-tripdata.zip</a>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the tag containing the desired information\n",
    "results = soup.find_all('a', class_='')\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e98d24-9663-4ff2-ac98-3aa4f74d6add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of years, and names for the subsequent lists\n",
    "years_list = []\n",
    "names_list = []\n",
    "\n",
    "for i in range(0, (len(results) - 1 )): # the \"-1\" will filter out index.html\n",
    "    \n",
    "    # extract the date\n",
    "    date = results[i][\"href\"].split('/')[-1].split('-')[0]\n",
    "    \n",
    "    # filter out Jersey City (JC) data\n",
    "    if (date != \"JC\"):\n",
    "        \n",
    "        # Extract the year\n",
    "        year = int(date[0:4])\n",
    "                \n",
    "        if (year not in years_list):\n",
    "            \n",
    "            # Add the found year to the years_list\n",
    "            years_list.append(year)\n",
    "            \n",
    "            # Create name, append to list\n",
    "            name = f\"data_{year}\"\n",
    "            names_list.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b0aaf9-9808-4457-9e73-07452133e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names_list:\n",
    "    globals()[f\"{name}\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ee2f16e-c79e-446d-9e51-5aeb0c1d5867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through every link in the list\n",
    "for i in range(0, (len(results) - 1 )): # the \"-1\" will filter out index.html\n",
    "    \n",
    "    # Find the date\n",
    "    date = results[i][\"href\"].split('/')[-1].split('-')[0]\n",
    "    \n",
    "    # filter out Jersey City (JC) data\n",
    "    if (date != \"JC\"):\n",
    "        \n",
    "        # Find the year\n",
    "        year = int(date[0:4])\n",
    "\n",
    "        # Loop through every list\n",
    "        for j in range (0, len(names_list)):\n",
    "\n",
    "            if (year == years_list[j]):\n",
    "                \n",
    "                # Append any applicable link to the list\n",
    "                globals()[f\"{names_list[j]}\"].append(results[i][\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf9e09d6-b03a-4f2b-bb0c-55fcf61ef305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose a year between 2013 and 2022: 2021\n"
     ]
    }
   ],
   "source": [
    "year_selection = input(f\"Choose a year between {years_list[0]} and {years_list[-1]}:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "248be780-978f-4c2b-8c38-4b8c8877f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = globals()[f\"data_{year_selection}\"]\n",
    "\n",
    "# Limit can be reduced for testing purposes, use len(selected_data) to run the remaining code for all files returned\n",
    "limit = len(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28ce9eb2-d9e4-4b59-b3e8-db6ea3a3b701",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [....................................................] 58640938 / 58640938"
     ]
    }
   ],
   "source": [
    "# Create lists of zip names and csv names to use when calling the file\n",
    "zip_names = []\n",
    "csv_names = []\n",
    "\n",
    "# for entry in results:\n",
    "for i in range(0, limit):\n",
    "    \n",
    "    # Get the link\n",
    "    link = selected_data[i]\n",
    "\n",
    "    # Use the link to get the zip and csv names, in case the .text is mismatched\n",
    "    zip_name = link.split('/')[-1]\n",
    "    zip_names.append(zip_name)\n",
    "\n",
    "    csv_name = zip_name.split('.')[0] + \".csv\"\n",
    "    csv_names.append(csv_name)\n",
    "   \n",
    "    # Download the zip\n",
    "    wget.download(link, out = \"zipfiles\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a50af4aa-6e05-404b-b472-bf9c88e0159b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emera\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (5,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\Users\\emera\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#Create CSVs\n",
    "\n",
    "#Set up the station information data frame and tracker list\n",
    "station_df = pd.DataFrame(columns = ['station_name', 'station_id', 'latitude', 'longitude'])\n",
    "station_names = []\n",
    "\n",
    "for i in range(1, limit):\n",
    "    \n",
    "    # find and read the zip file\n",
    "    find_zip = \"zipfiles/\" + zip_names[i]\n",
    "    zf = zipfile.ZipFile(find_zip)\n",
    "    df = pd.read_csv(zf.open(csv_names[i]))\n",
    "\n",
    "    # Add to the station_data df\n",
    "    for index, row in df.iterrows():\n",
    "        # Capturing station information from the start station\n",
    "        if row[\"start_station_name\"] not in station_names:\n",
    "            start_station_name = row[\"start_station_name\"] \n",
    "            start_station_id = row[\"start_station_id\"] \n",
    "            start_lat = row[\"start_lat\"]\n",
    "            start_lng = row[\"start_lng\"]\n",
    "            \n",
    "            # Append a new row\n",
    "            station_df = station_df.append({'station_name': start_station_name, 'station_id': start_station_id, 'latitude': start_lat, 'longitude': start_lng}, ignore_index = True)\n",
    "\n",
    "            # Add to the tracker list\n",
    "            station_names.append(start_station_name)\n",
    "\n",
    "    # Create new, smaller dataframe with extraneous station data removed\n",
    "    reduced_df = df[[\"ride_id\", \"rideable_type\", \"started_at\", \"ended_at\", \"start_station_id\", \"end_station_id\", \"member_casual\"]].copy()\n",
    "    \n",
    "    #create the csv\n",
    "    reduced_df.to_csv(\"data/\" + csv_names[i], index = False)\n",
    "\n",
    "#Save the station dataframe as a CSV\n",
    "station_df.to_csv(\"data/station_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3ee770f-6f5e-4401-8b2b-9bfa5f4a91aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>member_casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FA2F660C8D433037</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-03-04 18:58:36</td>\n",
       "      <td>2022-03-04 19:13:51</td>\n",
       "      <td>5847.08</td>\n",
       "      <td>5905.14</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03B6FE6FAEE61465</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-03-06 20:37:09</td>\n",
       "      <td>2022-03-06 20:45:28</td>\n",
       "      <td>5847.08</td>\n",
       "      <td>5914.03</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6E6995761B4A5760</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-03-01 15:13:49</td>\n",
       "      <td>2022-03-01 15:19:53</td>\n",
       "      <td>7522.02</td>\n",
       "      <td>7587.14</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA51CCF6CEDD6033</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-03-11 13:59:03</td>\n",
       "      <td>2022-03-11 14:06:43</td>\n",
       "      <td>6827.11</td>\n",
       "      <td>6929.02</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72AA3A7D430D8EF8</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-03-08 14:59:16</td>\n",
       "      <td>2022-03-08 15:05:04</td>\n",
       "      <td>6827.11</td>\n",
       "      <td>6929.02</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893439</th>\n",
       "      <td>79E49EA8727CA662</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-03-30 21:12:45</td>\n",
       "      <td>2022-03-30 21:22:15</td>\n",
       "      <td>6889.12</td>\n",
       "      <td>6762.02</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893440</th>\n",
       "      <td>9C4F6A095779AAE2</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-03-21 09:33:21</td>\n",
       "      <td>2022-03-21 09:39:45</td>\n",
       "      <td>6626.11</td>\n",
       "      <td>6762.02</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893441</th>\n",
       "      <td>C1966A89B5078124</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-03-04 14:31:36</td>\n",
       "      <td>2022-03-04 14:43:16</td>\n",
       "      <td>7354.01</td>\n",
       "      <td>6762.02</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893442</th>\n",
       "      <td>A11D1F167EF1B8C6</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2022-03-18 18:43:43</td>\n",
       "      <td>2022-03-18 18:53:41</td>\n",
       "      <td>6809.07</td>\n",
       "      <td>6762.02</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893443</th>\n",
       "      <td>74A6A40E386BE88F</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2022-03-10 17:21:52</td>\n",
       "      <td>2022-03-10 17:29:53</td>\n",
       "      <td>7100.07</td>\n",
       "      <td>6762.02</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1893444 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ride_id  rideable_type           started_at  \\\n",
       "0        FA2F660C8D433037  electric_bike  2022-03-04 18:58:36   \n",
       "1        03B6FE6FAEE61465   classic_bike  2022-03-06 20:37:09   \n",
       "2        6E6995761B4A5760   classic_bike  2022-03-01 15:13:49   \n",
       "3        AA51CCF6CEDD6033   classic_bike  2022-03-11 13:59:03   \n",
       "4        72AA3A7D430D8EF8   classic_bike  2022-03-08 14:59:16   \n",
       "...                   ...            ...                  ...   \n",
       "1893439  79E49EA8727CA662   classic_bike  2022-03-30 21:12:45   \n",
       "1893440  9C4F6A095779AAE2  electric_bike  2022-03-21 09:33:21   \n",
       "1893441  C1966A89B5078124  electric_bike  2022-03-04 14:31:36   \n",
       "1893442  A11D1F167EF1B8C6   classic_bike  2022-03-18 18:43:43   \n",
       "1893443  74A6A40E386BE88F  electric_bike  2022-03-10 17:21:52   \n",
       "\n",
       "                    ended_at start_station_id end_station_id member_casual  \n",
       "0        2022-03-04 19:13:51          5847.08        5905.14        member  \n",
       "1        2022-03-06 20:45:28          5847.08        5914.03        member  \n",
       "2        2022-03-01 15:19:53          7522.02        7587.14        member  \n",
       "3        2022-03-11 14:06:43          6827.11        6929.02        member  \n",
       "4        2022-03-08 15:05:04          6827.11        6929.02        member  \n",
       "...                      ...              ...            ...           ...  \n",
       "1893439  2022-03-30 21:22:15          6889.12        6762.02        member  \n",
       "1893440  2022-03-21 09:39:45          6626.11        6762.02        member  \n",
       "1893441  2022-03-04 14:43:16          7354.01        6762.02        member  \n",
       "1893442  2022-03-18 18:53:41          6809.07        6762.02        member  \n",
       "1893443  2022-03-10 17:29:53          7100.07        6762.02        casual  \n",
       "\n",
       "[1893444 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72af0f0f-6f68-4bf8-98c3-d82d35b6a9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>station_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington St &amp; Barrow St</td>\n",
       "      <td>5847.08</td>\n",
       "      <td>40.731911</td>\n",
       "      <td>-74.008769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 Ave &amp; E 110 St</td>\n",
       "      <td>7522.02</td>\n",
       "      <td>40.792327</td>\n",
       "      <td>-73.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crescent St &amp; Broadway</td>\n",
       "      <td>6827.11</td>\n",
       "      <td>40.763359</td>\n",
       "      <td>-73.928647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stagg St &amp; Union Ave</td>\n",
       "      <td>5117.05</td>\n",
       "      <td>40.708771</td>\n",
       "      <td>-73.950953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frost St &amp; Meeker Ave</td>\n",
       "      <td>5371.07</td>\n",
       "      <td>40.717662</td>\n",
       "      <td>-73.948800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>Cauldwell Ave &amp; E 158 St</td>\n",
       "      <td>7913.15</td>\n",
       "      <td>40.819890</td>\n",
       "      <td>-73.908351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>Townsend Ave &amp; E 175 St</td>\n",
       "      <td>8323.05</td>\n",
       "      <td>40.847410</td>\n",
       "      <td>-73.911359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>63 St &amp; 5 Ave</td>\n",
       "      <td>2872.02</td>\n",
       "      <td>40.637660</td>\n",
       "      <td>-74.017820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.670000</td>\n",
       "      <td>-73.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>Morgan WH station</td>\n",
       "      <td>SYS032</td>\n",
       "      <td>40.709873</td>\n",
       "      <td>-73.931594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1544 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   station_name station_id   latitude  longitude\n",
       "0     Washington St & Barrow St    5847.08  40.731911 -74.008769\n",
       "1              1 Ave & E 110 St    7522.02  40.792327 -73.938300\n",
       "2        Crescent St & Broadway    6827.11  40.763359 -73.928647\n",
       "3          Stagg St & Union Ave    5117.05  40.708771 -73.950953\n",
       "4         Frost St & Meeker Ave    5371.07  40.717662 -73.948800\n",
       "...                         ...        ...        ...        ...\n",
       "1539   Cauldwell Ave & E 158 St    7913.15  40.819890 -73.908351\n",
       "1540    Townsend Ave & E 175 St    8323.05  40.847410 -73.911359\n",
       "1541              63 St & 5 Ave    2872.02  40.637660 -74.017820\n",
       "1542                        NaN        NaN  40.670000 -73.970000\n",
       "1543          Morgan WH station     SYS032  40.709873 -73.931594\n",
       "\n",
       "[1544 rows x 4 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "station_df = pd.DataFrame(columns = ['station_name', 'station_id', 'latitude', 'longitude'])\n",
    "\n",
    "station_names = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    # Capturing station information from the start station\n",
    "    if row[\"start_station_name\"] not in station_names:\n",
    "        start_station_name = row[\"start_station_name\"] \n",
    "        start_station_id = row[\"start_station_id\"] \n",
    "        start_lat = row[\"start_lat\"]\n",
    "        start_lng = row[\"start_lng\"]\n",
    "    \n",
    "        station_df = station_df.append({'station_name': start_station_name, 'station_id': start_station_id, 'latitude': start_lat, 'longitude': start_lng}, ignore_index = True)\n",
    "    \n",
    "        station_names.append(start_station_name)\n",
    "\n",
    "station_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a81958a-7af7-4ffc-a43a-02983763d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df.to_csv(\"data/station_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "243597b4-7aff-4a79-8ca7-c14860cb957b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'202201-citibike-tripdata.csv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b434016-15e9-4fc5-b83b-a86612f902ed",
   "metadata": {},
   "source": [
    "### Next up: Turn all station info into a separate smaller csv/table, remove NULL values, ...remove outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee89a7-350b-4540-9ef0-26802a789648",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a3b39-bc3d-4aec-a189-c6012ac8e08f",
   "metadata": {},
   "source": [
    "### OLD Code with non-dynamic list names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4591a16-3fae-4b3f-8281-714c3151c3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://s3.amazonaws.com/tripdata/202201-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/202202-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/202203-citibike-tripdata.csv.zip']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2013to2016 = []\n",
    "data_2017 = []\n",
    "data_2018 = []\n",
    "data_2019 = []\n",
    "data_2020 = []\n",
    "data_2021 = []\n",
    "data_2022 = []\n",
    "\n",
    "\n",
    "for i in range(0, (len(results) - 1 )): # the \"-1\" will filter out index.html\n",
    "    date = results[i][\"href\"].split('/')[-1].split('-')[0]\n",
    "    \n",
    "    # filter out Jersey City (JC) data\n",
    "    if (date != \"JC\"):\n",
    "        year = int(date[0:4])\n",
    "        if (year <= 2016):\n",
    "            data_2013to2016.append(results[i][\"href\"])\n",
    "        elif (year == 2017):\n",
    "            data_2017.append(results[i][\"href\"])\n",
    "        elif (year == 2018):\n",
    "            data_2018.append(results[i][\"href\"])\n",
    "        elif (year == 2019):\n",
    "            data_2019.append(results[i][\"href\"])\n",
    "        elif (year == 2020):\n",
    "            data_2020.append(results[i][\"href\"])\n",
    "        elif (year == 2021):\n",
    "            data_2021.append(results[i][\"href\"])\n",
    "        elif (year == 2022):\n",
    "            data_2022.append(results[i][\"href\"])\n",
    "           \n",
    "            \n",
    "data_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a70f8365-0c92-4acd-aafd-4055091ac17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download zip files for a given year or year set\n",
    "data_list = data_2022\n",
    "\n",
    "limit = len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d33166fa-ff64-4130-8b47-ff2f6cf51ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [....................................................] 66434482 / 66434482"
     ]
    }
   ],
   "source": [
    "# Create lists of zip names and csv names to use when calling the file\n",
    "zip_names = []\n",
    "csv_names = []\n",
    "\n",
    "# for entry in results:\n",
    "for i in range(0, limit):\n",
    "    \n",
    "    # Get the link\n",
    "    link = data_list[i]\n",
    "\n",
    "    # Use the link to get the zip and csv names, in case the .text is mismatched\n",
    "    zip_name = link.split('/')[-1]\n",
    "    zip_names.append(zip_name)\n",
    "\n",
    "    csv_name = zip_name.split('.')[0] + \".csv\"\n",
    "    csv_names.append(csv_name)\n",
    "   \n",
    "    # Download the zip\n",
    "    wget.download(link, out = \"zipfiles\") \n",
    "    \n",
    "#     # Open and save as CSV\n",
    "#     df = pd.read_csv(zf.open(csv_names[i]))\n",
    "#     df.name = csv_names[i]\n",
    "#     df.to_csv(\"CSVs\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c66aa27c-3515-4390-8e3c-f52e59465b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emera\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (5,7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#Save as CSVs\n",
    "\n",
    "for i in range(0, limit):\n",
    "    \n",
    "    # find and read the zip file\n",
    "    find_zip = \"zipfiles/\" + zip_names[i]\n",
    "    zf = zipfile.ZipFile(find_zip)\n",
    "    df = pd.read_csv(zf.open(csv_names[i]))\n",
    "    \n",
    "    # name and create the csv\n",
    "    df.name = csv_names[i]\n",
    "    df.to_csv(\"data/\" + csv_names[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d49ad81-0d51-4b51-8424-8276ebd431a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"There is no item named '202202-citibike-tripdata.csv' in the archive\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-ede92c2def60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# find_zip = \"zipfiles/\" + zip_names[selected]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# zf = zipfile.ZipFile(find_zip)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselected\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, name, mode, pwd, force_zip64)\u001b[0m\n\u001b[0;32m   1512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m             \u001b[1;31m# Get info object for name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m             \u001b[0mzinfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36mgetinfo\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1439\u001b[0m         \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNameToInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m             raise KeyError(\n\u001b[0m\u001b[0;32m   1442\u001b[0m                 'There is no item named %r in the archive' % name)\n\u001b[0;32m   1443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"There is no item named '202202-citibike-tripdata.csv' in the archive\""
     ]
    }
   ],
   "source": [
    "selected = 1\n",
    "\n",
    "# find_zip = \"zipfiles/\" + zip_names[selected]\n",
    "# zf = zipfile.ZipFile(find_zip)\n",
    "df = pd.read_csv(zf.open(csv_names[selected]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90641fc0-497b-4421-9ed5-1d68e52b0aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
